<mxfile host="app.diagrams.net" agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36 SberBrowser/24.0.0.0" version="26.1.1">
  <diagram name="Страница — 1" id="I-Ke2cOXVvFwzJxJ1-Up">
    <mxGraphModel dx="1380" dy="738" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="827" pageHeight="1169" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <UserObject label="{&#xa; &quot;cells&quot;: [&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;07416ba6-134d-4b1e-905b-aacd355cb91e&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;import os\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;from dotenv import find_dotenv, load_dotenv&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;5f57d2d4-b264-4de9-bc06-c14307418060&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;load_dotenv(find_dotenv(&#39;.env&#39;))&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;66b88d20-563a-4ccb-bb28-6b6144d048b7&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;os.environ[\&quot;LANGCHAIN_PROJECT\&quot;] = \&quot;RAG From Scratch: Part 1 (Overview)\&quot;&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;9c35780a-28cd-4e73-a39c-b533dca92276&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;![](images/rag.png)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;66049591-4763-41c0-9f86-c1da026294a0&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;# Part 1: Overview&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;43f0b3d9-cb4c-4962-9a9a-d8775a72468c&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;![](images/01-01-overview.png)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;d592a47f-42df-4e4a-86da-65f245129e1c&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;![](images/01-02-overview.png)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;b0e3e69b-4bbc-41b6-8ffe-dbc4c5221ca3&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Configure components&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;590c8ee8-4228-4054-b312-f89e5ff6d635&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain_gigachat import GigaChat, GigaChatEmbeddings&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;f7db302d-e696-473d-b606-619182b1b308&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;GIGACHAT_API_BASE_URL = os.environ[\&quot;GIGACHAT_API_BASE_URL\&quot;]\n&quot;,&#xa;    &quot;GIGACHAT_API_USER = os.environ[\&quot;GIGACHAT_API_USER\&quot;]\n&quot;,&#xa;    &quot;GIGACHAT_API_PASSWORD = os.environ[\&quot;GIGACHAT_API_PASSWORD\&quot;]&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;bfb1e9b8-70e6-4490-bb8a-0d0a066c4683&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;llm = GigaChat(\n&quot;,&#xa;    &quot;    model=\&quot;GigaChat-2-Max\&quot;,\n&quot;,&#xa;    &quot;    base_url=GIGACHAT_API_BASE_URL,\n&quot;,&#xa;    &quot;    user=GIGACHAT_API_USER,\n&quot;,&#xa;    &quot;    password=GIGACHAT_API_PASSWORD,\n&quot;,&#xa;    &quot;    verify_ssl_certs=False,\n&quot;,&#xa;    &quot;    profanity_check=False,\n&quot;,&#xa;    &quot;)\n&quot;,&#xa;    &quot;llm.invoke(\&quot;Hello\&quot;)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;c2bdeebb-3875-4fdd-97be-346c92eeb240&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;embeddings = GigaChatEmbeddings(\n&quot;,&#xa;    &quot;    model=\&quot;EmbeddingsGigaR\&quot;,\n&quot;,&#xa;    &quot;    base_url=GIGACHAT_API_BASE_URL,\n&quot;,&#xa;    &quot;    user=GIGACHAT_API_USER,\n&quot;,&#xa;    &quot;    password=GIGACHAT_API_PASSWORD,\n&quot;,&#xa;    &quot;    verify_ssl_certs=False,\n&quot;,&#xa;    &quot;)\n&quot;,&#xa;    &quot;len(embeddings.embed_query(\&quot;Hello\&quot;))&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;9ca63ab0-004c-4f93-b0e6-a06c7e84c3ed&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Load documents&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;5b127b80-4839-4edd-9b6e-1a55a90a3fba&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;import bs4\n&quot;,&#xa;    &quot;from langchain_community.document_loaders import WebBaseLoader&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;e29df1f8-327a-437a-85f9-d87867cbfd28&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;loader = WebBaseLoader(\n&quot;,&#xa;    &quot;    web_paths=(\&quot;https://lilianweng.github.io/posts/2023-06-23-agent/\&quot;,),\n&quot;,&#xa;    &quot;    bs_kwargs=dict(\n&quot;,&#xa;    &quot;        parse_only=bs4.SoupStrainer(\n&quot;,&#xa;    &quot;            class_=(\&quot;post-content\&quot;, \&quot;post-title\&quot;, \&quot;post-header\&quot;)\n&quot;,&#xa;    &quot;        )\n&quot;,&#xa;    &quot;    ),\n&quot;,&#xa;    &quot;)\n&quot;,&#xa;    &quot;docs = loader.load()\n&quot;,&#xa;    &quot;len(docs)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;2d06a9e8-aeab-4b37-8ac4-20279c0802af&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;print(docs[0].page_content[:1000])&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;1aff715e-f153-486a-9e4a-85ae300b03e7&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Split documents&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;8621acc3-5ab8-4f70-a2cb-171795bcf9cb&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain.text_splitter import RecursiveCharacterTextSplitter&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;3143439a-0271-4ad1-8f9b-78cd2a631098&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n&quot;,&#xa;    &quot;splits = text_splitter.split_documents(docs)\n&quot;,&#xa;    &quot;len(splits)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;05600430-cf93-4429-92ea-ca183ec2310c&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Store documents&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;e13dd7d7-06d6-47ef-8251-ea0ec7dec665&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain_core.vectorstores import InMemoryVectorStore&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;c49eece0-d92c-47ac-8db5-bd36e6eb185e&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;vectorstore = InMemoryVectorStore(embeddings)\n&quot;,&#xa;    &quot;doc_ids = vectorstore.add_documents(documents=splits)\n&quot;,&#xa;    &quot;len(doc_ids), len(vectorstore.store)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;06c4043d-c52d-4148-b583-d67d628dbff5&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## RAG&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;6cfd3b01-4e08-4c30-bacf-b4c24315d1a6&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;rag_prompt_template = \&quot;\&quot;\&quot;You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don&#39;t know the answer, just say that you don&#39;t know. Use three sentences maximum and keep the answer concise.\n&quot;,&#xa;    &quot;Question: {question} \n&quot;,&#xa;    &quot;Context: {context} \n&quot;,&#xa;    &quot;Answer:\&quot;\&quot;\&quot;\n&quot;,&#xa;    &quot;print(rag_prompt_template)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;a7d761fb-1ac8-41b8-b085-7584243083a5&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;def format_docs(docs):\n&quot;,&#xa;    &quot;    return \&quot;\\n\\n\&quot;.join(doc.page_content for doc in docs)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;bbc1649a-4f84-4f07-9531-f63e4fc88af3&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;### LangChain&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;78d233d1-7f6d-417a-a670-728db23dde67&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain_core.output_parsers import StrOutputParser\n&quot;,&#xa;    &quot;from langchain_core.prompts import ChatPromptTemplate\n&quot;,&#xa;    &quot;from langchain_core.runnables import RunnablePassthrough&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;e76c12eb-73a5-45d9-8d79-78dbca1818f7&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;ebf1d3cc-c57d-4fcb-8dff-fcd18fed3231&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;retriever = vectorstore.as_retriever()\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;chain = (\n&quot;,&#xa;    &quot;    {\n&quot;,&#xa;    &quot;        \&quot;context\&quot;: retriever | format_docs, \n&quot;,&#xa;    &quot;        \&quot;question\&quot;: RunnablePassthrough()\n&quot;,&#xa;    &quot;    }\n&quot;,&#xa;    &quot;    | rag_prompt\n&quot;,&#xa;    &quot;    | llm\n&quot;,&#xa;    &quot;    | StrOutputParser()\n&quot;,&#xa;    &quot;)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;d65b55f9-3624-41e8-8699-1fd9b2eaab55&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;response = chain.invoke(\&quot;What is Task Decomposition?\&quot;)\n&quot;,&#xa;    &quot;print(response)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;8dc1562a-7954-4f61-9b5f-9b5d840a8d58&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;### LangGraph&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;561288ac-3b88-4ef0-a4df-9e3ce2d5f029&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from typing import TypedDict\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;from langchain_core.documents import Document\n&quot;,&#xa;    &quot;from langchain_core.messages import HumanMessage\n&quot;,&#xa;    &quot;from langgraph.graph import END, START, StateGraph&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;52e36a6b-474e-4d75-9a72-31f6c05e2f7b&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;class State(TypedDict):\n&quot;,&#xa;    &quot;    question: str\n&quot;,&#xa;    &quot;    context: list[Document]\n&quot;,&#xa;    &quot;    answer: str&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;708e72c8-6cc2-4d87-ac99-a89d6dba7e2e&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;def retrieve(state: State):\n&quot;,&#xa;    &quot;    retrieved_docs = vectorstore.similarity_search(state[\&quot;question\&quot;])\n&quot;,&#xa;    &quot;    return {\&quot;context\&quot;: retrieved_docs}\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;def generate(state: State):\n&quot;,&#xa;    &quot;    docs_content = format_docs(state[\&quot;context\&quot;])\n&quot;,&#xa;    &quot;    rag_prompt = rag_prompt_template.format(\n&quot;,&#xa;    &quot;        question=state[\&quot;question\&quot;],\n&quot;,&#xa;    &quot;        context=docs_content\n&quot;,&#xa;    &quot;    )\n&quot;,&#xa;    &quot;    response = llm.invoke([\n&quot;,&#xa;    &quot;        HumanMessage(content=rag_prompt)\n&quot;,&#xa;    &quot;    ])\n&quot;,&#xa;    &quot;    return {\&quot;answer\&quot;: response.content}\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n&quot;,&#xa;    &quot;graph_builder.add_edge(START, \&quot;retrieve\&quot;)\n&quot;,&#xa;    &quot;graph_builder.add_edge(\&quot;generate\&quot;, END)\n&quot;,&#xa;    &quot;graph = graph_builder.compile()\n&quot;,&#xa;    &quot;graph&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;5faffc5a-bf35-4891-a23c-4696c12ce831&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;response = graph.invoke({\&quot;question\&quot;: \&quot;What is Task Decomposition?\&quot;})\n&quot;,&#xa;    &quot;print(response[\&quot;answer\&quot;])&quot;&#xa;   ]&#xa;  }&#xa; ],&#xa; &quot;metadata&quot;: {&#xa;  &quot;kernelspec&quot;: {&#xa;   &quot;display_name&quot;: &quot;Python 3 (ipykernel)&quot;,&#xa;   &quot;language&quot;: &quot;python&quot;,&#xa;   &quot;name&quot;: &quot;python3&quot;&#xa;  },&#xa;  &quot;language_info&quot;: {&#xa;   &quot;codemirror_mode&quot;: {&#xa;    &quot;name&quot;: &quot;ipython&quot;,&#xa;    &quot;version&quot;: 3&#xa;   },&#xa;   &quot;file_extension&quot;: &quot;.py&quot;,&#xa;   &quot;mimetype&quot;: &quot;text/x-python&quot;,&#xa;   &quot;name&quot;: &quot;python&quot;,&#xa;   &quot;nbconvert_exporter&quot;: &quot;python&quot;,&#xa;   &quot;pygments_lexer&quot;: &quot;ipython3&quot;,&#xa;   &quot;version&quot;: &quot;3.11.11&quot;&#xa;  }&#xa; },&#xa; &quot;nbformat&quot;: 4,&#xa; &quot;nbformat_minor&quot;: 5&#xa;}" link="{&#xa; &quot;cells&quot;: [&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;07416ba6-134d-4b1e-905b-aacd355cb91e&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;import os\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;from dotenv import find_dotenv, load_dotenv&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;5f57d2d4-b264-4de9-bc06-c14307418060&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;load_dotenv(find_dotenv(&#39;.env&#39;))&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;66b88d20-563a-4ccb-bb28-6b6144d048b7&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;os.environ[\&quot;LANGCHAIN_PROJECT\&quot;] = \&quot;RAG From Scratch: Part 1 (Overview)\&quot;&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;9c35780a-28cd-4e73-a39c-b533dca92276&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;![](images/rag.png)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;66049591-4763-41c0-9f86-c1da026294a0&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;# Part 1: Overview&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;43f0b3d9-cb4c-4962-9a9a-d8775a72468c&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;![](images/01-01-overview.png)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;d592a47f-42df-4e4a-86da-65f245129e1c&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;![](images/01-02-overview.png)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;b0e3e69b-4bbc-41b6-8ffe-dbc4c5221ca3&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Configure components&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;590c8ee8-4228-4054-b312-f89e5ff6d635&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain_gigachat import GigaChat, GigaChatEmbeddings&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;f7db302d-e696-473d-b606-619182b1b308&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;GIGACHAT_API_BASE_URL = os.environ[\&quot;GIGACHAT_API_BASE_URL\&quot;]\n&quot;,&#xa;    &quot;GIGACHAT_API_USER = os.environ[\&quot;GIGACHAT_API_USER\&quot;]\n&quot;,&#xa;    &quot;GIGACHAT_API_PASSWORD = os.environ[\&quot;GIGACHAT_API_PASSWORD\&quot;]&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;bfb1e9b8-70e6-4490-bb8a-0d0a066c4683&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;llm = GigaChat(\n&quot;,&#xa;    &quot;    model=\&quot;GigaChat-2-Max\&quot;,\n&quot;,&#xa;    &quot;    base_url=GIGACHAT_API_BASE_URL,\n&quot;,&#xa;    &quot;    user=GIGACHAT_API_USER,\n&quot;,&#xa;    &quot;    password=GIGACHAT_API_PASSWORD,\n&quot;,&#xa;    &quot;    verify_ssl_certs=False,\n&quot;,&#xa;    &quot;    profanity_check=False,\n&quot;,&#xa;    &quot;)\n&quot;,&#xa;    &quot;llm.invoke(\&quot;Hello\&quot;)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;c2bdeebb-3875-4fdd-97be-346c92eeb240&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;embeddings = GigaChatEmbeddings(\n&quot;,&#xa;    &quot;    model=\&quot;EmbeddingsGigaR\&quot;,\n&quot;,&#xa;    &quot;    base_url=GIGACHAT_API_BASE_URL,\n&quot;,&#xa;    &quot;    user=GIGACHAT_API_USER,\n&quot;,&#xa;    &quot;    password=GIGACHAT_API_PASSWORD,\n&quot;,&#xa;    &quot;    verify_ssl_certs=False,\n&quot;,&#xa;    &quot;)\n&quot;,&#xa;    &quot;len(embeddings.embed_query(\&quot;Hello\&quot;))&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;9ca63ab0-004c-4f93-b0e6-a06c7e84c3ed&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Load documents&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;5b127b80-4839-4edd-9b6e-1a55a90a3fba&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;import bs4\n&quot;,&#xa;    &quot;from langchain_community.document_loaders import WebBaseLoader&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;e29df1f8-327a-437a-85f9-d87867cbfd28&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;loader = WebBaseLoader(\n&quot;,&#xa;    &quot;    web_paths=(\&quot;https://lilianweng.github.io/posts/2023-06-23-agent/\&quot;,),\n&quot;,&#xa;    &quot;    bs_kwargs=dict(\n&quot;,&#xa;    &quot;        parse_only=bs4.SoupStrainer(\n&quot;,&#xa;    &quot;            class_=(\&quot;post-content\&quot;, \&quot;post-title\&quot;, \&quot;post-header\&quot;)\n&quot;,&#xa;    &quot;        )\n&quot;,&#xa;    &quot;    ),\n&quot;,&#xa;    &quot;)\n&quot;,&#xa;    &quot;docs = loader.load()\n&quot;,&#xa;    &quot;len(docs)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;2d06a9e8-aeab-4b37-8ac4-20279c0802af&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;print(docs[0].page_content[:1000])&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;1aff715e-f153-486a-9e4a-85ae300b03e7&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Split documents&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;8621acc3-5ab8-4f70-a2cb-171795bcf9cb&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain.text_splitter import RecursiveCharacterTextSplitter&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;3143439a-0271-4ad1-8f9b-78cd2a631098&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n&quot;,&#xa;    &quot;splits = text_splitter.split_documents(docs)\n&quot;,&#xa;    &quot;len(splits)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;05600430-cf93-4429-92ea-ca183ec2310c&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## Store documents&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;e13dd7d7-06d6-47ef-8251-ea0ec7dec665&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain_core.vectorstores import InMemoryVectorStore&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;c49eece0-d92c-47ac-8db5-bd36e6eb185e&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;vectorstore = InMemoryVectorStore(embeddings)\n&quot;,&#xa;    &quot;doc_ids = vectorstore.add_documents(documents=splits)\n&quot;,&#xa;    &quot;len(doc_ids), len(vectorstore.store)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;06c4043d-c52d-4148-b583-d67d628dbff5&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;## RAG&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;6cfd3b01-4e08-4c30-bacf-b4c24315d1a6&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;rag_prompt_template = \&quot;\&quot;\&quot;You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don&#39;t know the answer, just say that you don&#39;t know. Use three sentences maximum and keep the answer concise.\n&quot;,&#xa;    &quot;Question: {question} \n&quot;,&#xa;    &quot;Context: {context} \n&quot;,&#xa;    &quot;Answer:\&quot;\&quot;\&quot;\n&quot;,&#xa;    &quot;print(rag_prompt_template)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;a7d761fb-1ac8-41b8-b085-7584243083a5&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;def format_docs(docs):\n&quot;,&#xa;    &quot;    return \&quot;\\n\\n\&quot;.join(doc.page_content for doc in docs)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;bbc1649a-4f84-4f07-9531-f63e4fc88af3&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;### LangChain&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;78d233d1-7f6d-417a-a670-728db23dde67&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from langchain_core.output_parsers import StrOutputParser\n&quot;,&#xa;    &quot;from langchain_core.prompts import ChatPromptTemplate\n&quot;,&#xa;    &quot;from langchain_core.runnables import RunnablePassthrough&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;e76c12eb-73a5-45d9-8d79-78dbca1818f7&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;ebf1d3cc-c57d-4fcb-8dff-fcd18fed3231&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;retriever = vectorstore.as_retriever()\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;chain = (\n&quot;,&#xa;    &quot;    {\n&quot;,&#xa;    &quot;        \&quot;context\&quot;: retriever | format_docs, \n&quot;,&#xa;    &quot;        \&quot;question\&quot;: RunnablePassthrough()\n&quot;,&#xa;    &quot;    }\n&quot;,&#xa;    &quot;    | rag_prompt\n&quot;,&#xa;    &quot;    | llm\n&quot;,&#xa;    &quot;    | StrOutputParser()\n&quot;,&#xa;    &quot;)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;d65b55f9-3624-41e8-8699-1fd9b2eaab55&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;response = chain.invoke(\&quot;What is Task Decomposition?\&quot;)\n&quot;,&#xa;    &quot;print(response)&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;markdown&quot;,&#xa;   &quot;id&quot;: &quot;8dc1562a-7954-4f61-9b5f-9b5d840a8d58&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;source&quot;: [&#xa;    &quot;### LangGraph&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;561288ac-3b88-4ef0-a4df-9e3ce2d5f029&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;from typing import TypedDict\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;from langchain_core.documents import Document\n&quot;,&#xa;    &quot;from langchain_core.messages import HumanMessage\n&quot;,&#xa;    &quot;from langgraph.graph import END, START, StateGraph&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;52e36a6b-474e-4d75-9a72-31f6c05e2f7b&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;class State(TypedDict):\n&quot;,&#xa;    &quot;    question: str\n&quot;,&#xa;    &quot;    context: list[Document]\n&quot;,&#xa;    &quot;    answer: str&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;708e72c8-6cc2-4d87-ac99-a89d6dba7e2e&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;def retrieve(state: State):\n&quot;,&#xa;    &quot;    retrieved_docs = vectorstore.similarity_search(state[\&quot;question\&quot;])\n&quot;,&#xa;    &quot;    return {\&quot;context\&quot;: retrieved_docs}\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;def generate(state: State):\n&quot;,&#xa;    &quot;    docs_content = format_docs(state[\&quot;context\&quot;])\n&quot;,&#xa;    &quot;    rag_prompt = rag_prompt_template.format(\n&quot;,&#xa;    &quot;        question=state[\&quot;question\&quot;],\n&quot;,&#xa;    &quot;        context=docs_content\n&quot;,&#xa;    &quot;    )\n&quot;,&#xa;    &quot;    response = llm.invoke([\n&quot;,&#xa;    &quot;        HumanMessage(content=rag_prompt)\n&quot;,&#xa;    &quot;    ])\n&quot;,&#xa;    &quot;    return {\&quot;answer\&quot;: response.content}\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;\n&quot;,&#xa;    &quot;graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n&quot;,&#xa;    &quot;graph_builder.add_edge(START, \&quot;retrieve\&quot;)\n&quot;,&#xa;    &quot;graph_builder.add_edge(\&quot;generate\&quot;, END)\n&quot;,&#xa;    &quot;graph = graph_builder.compile()\n&quot;,&#xa;    &quot;graph&quot;&#xa;   ]&#xa;  },&#xa;  {&#xa;   &quot;cell_type&quot;: &quot;code&quot;,&#xa;   &quot;execution_count&quot;: null,&#xa;   &quot;id&quot;: &quot;5faffc5a-bf35-4891-a23c-4696c12ce831&quot;,&#xa;   &quot;metadata&quot;: {},&#xa;   &quot;outputs&quot;: [],&#xa;   &quot;source&quot;: [&#xa;    &quot;response = graph.invoke({\&quot;question\&quot;: \&quot;What is Task Decomposition?\&quot;})\n&quot;,&#xa;    &quot;print(response[\&quot;answer\&quot;])&quot;&#xa;   ]&#xa;  }&#xa; ],&#xa; &quot;metadata&quot;: {&#xa;  &quot;kernelspec&quot;: {&#xa;   &quot;display_name&quot;: &quot;Python 3 (ipykernel)&quot;,&#xa;   &quot;language&quot;: &quot;python&quot;,&#xa;   &quot;name&quot;: &quot;python3&quot;&#xa;  },&#xa;  &quot;language_info&quot;: {&#xa;   &quot;codemirror_mode&quot;: {&#xa;    &quot;name&quot;: &quot;ipython&quot;,&#xa;    &quot;version&quot;: 3&#xa;   },&#xa;   &quot;file_extension&quot;: &quot;.py&quot;,&#xa;   &quot;mimetype&quot;: &quot;text/x-python&quot;,&#xa;   &quot;name&quot;: &quot;python&quot;,&#xa;   &quot;nbconvert_exporter&quot;: &quot;python&quot;,&#xa;   &quot;pygments_lexer&quot;: &quot;ipython3&quot;,&#xa;   &quot;version&quot;: &quot;3.11.11&quot;&#xa;  }&#xa; },&#xa; &quot;nbformat&quot;: 4,&#xa; &quot;nbformat_minor&quot;: 5&#xa;}" id="jb5V0V8CM6rSmirHjqXn-1">
          <mxCell style="text;whiteSpace=wrap;html=1;" vertex="1" parent="1">
            <mxGeometry x="150" y="320" width="560" height="6270" as="geometry" />
          </mxCell>
        </UserObject>
      </root>
    </mxGraphModel>
  </diagram>
</mxfile>
